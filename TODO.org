* Components
** Delta Acts
 - Goal states, a set of methods (planboxes) for achieving goal states, and a decision procedure for ordering/prioritizing methods for achieving goals
 - Results ultimately in an action module activating
*** Example - DeltaProx
**** Planbox 0: Does X think that Y is already near Z?
** Planboxes
 - Has preconditions which define whether they can be used at all, or used before/after other planboxes
 - "Unconscious" preconditions - would never occur to you to try them
 - "Uncontrollable" preconditions - cannot be made true by the actor if they are already true
 - "Plantime" preconditions - preconditions evaluated at time of planbox selection (plantime)
 - "Social" preconditions - take into account social dynamics
 - "Contextual" preconditions - ensure that plans do not undo goals already achieved in the pursuit of the final goal
** Sigma States
 - Physical needs which must be satisfied.
 - Unlike delta-acts they are not nested as subgoals of another goal. They arise spontaneously and periodically.
** Action Modules - Create side effects in the world
 - PTRANS
 - MTRANS
 - ATRANS
** Assertion Mechanism
 - Called by action modules - records the fact of an occurance
** Reaction modules
 - Usually knowledge propagation inferences

* Our implementation
** Classes
*** Planbox
 - Preconditions - Triples that must be true
 - action
 - Postconditions
 - Postact
*** Action Module

* TO DO

** STARTED Make kaze find food
 - Actors evaluate options and choose strategies when sigma states activate
** TODO Make kaze eat food

* Done
** DONE Write tests for Graph class before you write any more damn code
   CLOSED: [2015-11-05 Thu 23:24]

** DONE Fix bug with place names in ptrans not showing up
   CLOSED: [2015-11-05 Thu 23:25]

** DONE Add bread - bread is food
   CLOSED: [2015-11-06 Fri 12:18]
 - Add item class
 - Items have properties in the form of triples?
 - Knowledge graph represents the properties known by actors at simulation init

** DONE Add FindFood delta act
   CLOSED: [2015-11-06 Fri 16:18]


We need to be able to 
- parameterize data to delta acts on instantiation
- have parameterized data passed into planbox INSTANCES from deltas
- decompose delta acts into planboxes
- Figure out how to prioritize/order planboxes when executing a 'strategy' (delta action)

### Idea re: planboxes/reuse

Since most delta actions consist of multiple planboxes, planboxes will need to be able to change the state of their parent delta action after completion. Planbox inclusion in a delta action could then be defined in terms of its requirements with respect to that specific delta action. For example, in order to find food.
```
planbox PickDestination, decision_proc: Proc.new { |actor| actor.location.exits.sample }

planbox MoveSelfToOtherLocation, contingency: Proc.new { |delta_state| delta_state.destination } # Can only be activated if the agent has chosen a state first
```
Notice that we've also added a 'decision_proc' to a planbox - this could be an optional way to override default planbox behavior, but this is a can of worms that we shouldn't open yet. My thinking is that 'PickDestination' is a generic planbox that would need to be very heavily parameterized per delta action - if an actor is looking to, say, buy drugs, they wouldn't pick a destination arbitrarily, whereas if they were lost in the desert, they more than likely would. Therefore how do we get more mileage out of planboxes? Parameterize decision logic if needed. But _the decision logic for a planbox will be where the reasoning and knowledgebase search will occur_, so we don't want to lock ourselves into that highly advanced portion of the design until ready.

NOTE: Forget the above crap i just said - PER MEEHAN, planboxes have preconditions, postconditions, and postactions - while we'll want to be able to add more at the delta action level as described above, its important to try and implement things as Meehan did first.

### Re: 'env' on planboxes -> actions

The idea with the badly-named 'env' method on Planboxes::Base was that it would transform the actor/other state and deliver it to the action - for example in the PerceiveItemsAtLocation class, it maps each item at the agent's location to a triple, and then passes those to the action, which performs the actual 'learning' of those facts...

So since then I've been passing the same stuff down the chain of behavior execution: agent, delta, sigma. Also, I've decided to keep any extraneous state that needs to persist _between components of a delta action or sigma state resolution_ on the sigma state instance itself. So this begs the question - should I just put the transformation into the sigma.state hash? To do that, I'd change the env method to accept a key to store the result in, and then a proc.

I think this is a bad idea because the action _doesnt need to know about all that crap_. Pete Schall's words coming out of my mouth :P BUT, we could just pass the sigma state to the action...Still too much information, I reckon...
